To show that (6) defines a sequence of continuously differentiable strictly increasing concave functions {cT , cT −1 , ..., cT −k }, we start with a definition. We will say
that a function n(z) is ‘nice’ if it satisfies
1. n(z) is well-defined iff z > 0
2. n(z) is strictly increasing
3. n(z) is strictly concave
4. n(z) is C3
5. n(z) < 0
6. limz↓0 n(z) = −∞.
(Notice that an implication of niceness is that limz↓0 n0 (z) = ∞.)
Assume that some vt+1 is nice. Our objective is to show that this implies vt is
also nice; this is sufficient to establish that vt−n is nice by induction for all n > 0
because vT (m) = u(m) and u(m) = m1−ρ /(1 − ρ) is nice by inspection.
Now define an end-of-period value function vt (a) as
i

h

vt (a) = β Et Γ1−ρ
t+1 vt+1 (Rt+1 a + ξt+1 ) .

(1)

Since there is a positive probability that ξt+1 will attain its minimum of zero
and since Rt+1 > 0, it is clear that lima↓0 vt (a) = −∞ and lima↓0 v0t (a) = ∞. So
vt (a) is well-defined iff a > 0; it is similarly straightforward to show the other
properties required for vt (a) to be nice. (See Hiraguchi (2003).)
Next define vt (m, c) as
vt (m, c) = u(c) + vt (m − c)

(2)

which is C3 since vt and u are both C3 , and note that our problem’s value function
defined in (6) can be written as
vt (m) = max vt (m, c).
c

(3)

vt is well-defined if and only if 0 < c < m. Furthermore, limc↓0 vt (m, c) =
∂ 2 vt (m,c)
∂v (m,c)
∂v (m,c)
limc↑m vt (m, c) = −∞,
< 0, limc↓0 t∂c
= +∞, and limc↑m t∂c
=
∂c2
−∞. It follows that the ct (m) defined by
ct (m) = arg max vt (m, c)

(4)

0<c<m

exists and is unique, and (6) has an internal solution that satisfies
u0 (ct (m)) = v0t (m − ct (m)).

(5)

Since both u and vt are strictly concave, both ct (m) and at (m) = m − ct (m) are
strictly increasing. Since both u and vt are three times continuously differentiable,
using (5) we can conclude that ct (m) is continuously differentiable and
c0t (m) =

v00t (at (m))
.
u00 (ct (m)) + v00t (at (m))

(6)

Similarly we can easily show that ct (m) is twice continuously differentiable
(as is at (m)) (See Appendix 2.) This implies that vt (m) is nice, since vt (m) =
u(ct (m)) + vt (at (m)).

2 ct(m) is Twice Continuously Differentiable
First we show that ct (m) is C1 . Define y as y ≡ m+dm. Since u0 (ct (y))−u0 (ct (m)) =
t (m)
t (m)
= 1 − ct (y)−c
,
v0t (at (y)) − v0t (at (m)) and at (y)−a
dm
dm
v0t (at (y)) − v0t (at (m))
=
at (y) − at (m)

u0 (ct (y)) − u0 (ct (m)) v0t (at (y)) − v0t (at (m))
+
ct (y) − ct (m)
at (y) − at (m)

Since ct and at are continuous and increasing,
v0t (at (y))−v0t (at (m))
at (y)−at (m)
dm→+0

lim

< 0 are satisfied. Then

u0 (ct (y))−u0 (ct (m))
ct (y)−ct (m)
dm→+0

lim

u0 (ct (y))−u0 (ct (m))
+
ct (y)−ct (m)

!

ct (y) − ct (m)
dm

< 0 and

v0t (at (y))−v0t (at (m))
at (y)−at (m)

<0

for sufficiently small dm. Hence we obtain a well-defined equation:
ct (y) − ct (m)
=
dm

v0t (at (y))−v0t (at (m))
at (y)−at (m)
.
v0t (at (y))−v0t (at (m))
u0 (ct (y))−u0 (ct (m))
+
ct (y)−ct (m)
at (y)−at (m)

This implies that the right-derivative, c0+
t (m) is well-defined and
c0+
t (m) =

v00t (at (m))
.
u00 (ct (m)) + v00t (at (m))

0−
0
Similarly we can show that c0+
t (m) = ct (m), which means ct (m) exists. Since
vt is C3 , c0t (m) exists and is continuous. c0t (m) is differentiable because v00t is C1 ,
ct (m) is C1 and u00 (ct (m)) + v00t (at (m)) < 0. c00t (m) is given by

c00t (m) =

00
00
00
0 000
0 000
a0t (m)v000
t (at ) [u (ct ) + vt (at )] − vt (at ) [ct u (ct ) + at vt (at )]
.
[u00 (ct ) + v00t (at )]2

(7)

Since v00t (at (m)) is continuous, c00t (m) is also continuous.

3 Proof that T Is a Contraction Mapping
We must show that our operator T satisfies all of Boyd’s conditions.
Boyd’s operator T maps from Cz (A, B) to C(A, B). A preliminary requirement
is therefore that {Tz} be continuous for any z−bounded z, {Tz} ∈ C(R++ , R).
This is not difficult to show; see Hiraguchi (2003).
Consider condition (1). For this problem,
{Tx}(mt ) is
{Ty}(mt ) is

max

n

h

io

max

n

h

io

ct ∈[κmt ,κ̄mt ]
ct ∈[κmt ,κ̄mt ]

u(ct ) + β Et Γ1−ρ
t+1 x (mt+1 )
u(ct ) + β Et Γ1−ρ
t+1 y (mt+1 )

2

,

so x(•) ≤ y(•) implies {Tx}(mt ) ≤ {Ty}(mt ) by inspection.1
Condition (2) requires that {T0} ∈ Cz (A, B). By definition,
(

{T0}(mt ) =

max

ct ∈[κmt ,κ̄mt ]

c1−ρ
t
+ β0
1−ρ
!

)

the solution to which is patently u(κ̄mt ). Thus, condition (2) will hold if (κ̄mt )1−ρ
is z-bounded. We use the bounding function
z(m) = η + m1−ρ ,

(8)

for some real scalar η > 0 whose value will be determined in the course of the
proof. Under this definition of z, {T0}(mt ) = u(κ̄mt ) is clearly z-bounded.
Finally, we turn to condition (3), {T(z + ζz)}(mt ) ≤ {Tz}(mt ) + ζαz(mt ).
The proof will be more compact if we define c̆ and ă as the consumption and
assets functions2 associated with Tz and ĉ and â as the functions associated with
T(z + ζz); using this notation, condition (3) can be rewritten
u(ĉ) + β{E(z + ζz)}(â) ≤ u(c̆) + β{Ez}(ă) + ζαz.
Now note that if we force the ^ consumer to consume the amount that is
optimal for the ∧ consumer, value for the ^ consumer must decline (at least
weakly). That is,
u(ĉ) + β{Ez}(â) ≤ u(c̆) + β{Ez}(ă).
Thus, condition (3) will certainly hold under the stronger condition
u(ĉ) + β{E(z + ζz)}(â) ≤ u(ĉ) + β{Ez}(â) + ζαz
β{E(z + ζz)}(â) ≤ β{Ez}(â) + ζαz
βζ{Ez}(â) ≤ ζαz
β{Ez}(â) ≤ αz
β{Ez}(â) < z.
where the last line follows because 0 < α < 1 by assumption.3
Using z(m) = η + m1−ρ and defining ât = â(mt ), this condition is
1−ρ
1−ρ
)
β Et [Γ1−ρ
] − mt1−ρ < η(1 − β Et Γt+1
t+1 (ât Rt+1 + ξt+1 )

|

{z

=i

}

which by imposing PF-FVAC (equation (27), which says i < 1) can be rewritten
as:
h

i

1−ρ
β Et Γ1−ρ
− m1−ρ
t
t+1 (ât Rt+1 + ξt+1 )

.
(9)
1−i
But since η is an arbitrary constant that we can pick, the proof thus reduces to
η>

1

For a fixed mt , recall that mt+1 is just a function of ct and the stochastic shocks.
Section 2.7 proves existence of a continuously differentiable consumption function, which
implies the existence of a corresponding continuously differentiable assets function.
3
The remainder of the proof could be reformulated using the second-to-last line at a small
cost to intuition.
2

3

showing that the numerator of (9) is bounded from above:
h

i

h

i

1−ρ
1−ρ
(1 − ℘)β Et Γ1−ρ
+ ℘β Et Γ1−ρ
− m1−ρ
t
t+1 (ât Rt+1 + θt+1 /(1 − ℘))
t+1 (ât Rt+1 )

h

i

1−ρ
≤(1 − ℘)β Et Γ1−ρ
+ ℘βR1−ρ ((1 − κ̄)mt )1−ρ − m1−ρ
t
t+1 ((1 − κ̄)mt Rt+1 + θt+1 /(1 − ℘))



=(1 − ℘)β

h

Et Γ1−ρ
t+1 ((1

1−ρ

− κ̄)mt Rt+1 + θt+1 /(1 − ℘))

h

i

+

i

m1−ρ
t

1−ρ

℘βR

℘

1/ρ
1/ρ (Rβ)










(Rβ)1/ρ

−1

{z R }

1−ρ
℘1/ρ
=(1 − ℘)β Et Γ1−ρ
+ m1−ρ
t
t+1 ((1 − κ̄)mt Rt+1 + θt+1 /(1 − ℘))

|

<1 by WRIC

(10)
h

i

1−ρ
<(1 − ℘)β Et Γ1−ρ
= i(1 − ℘)ρ θ1−ρ .
t+1 (θ/(1 − ℘))

We can thus conclude that equation (9) will certainly hold for any:
i(1 − ℘)ρ θ1−ρ
η>η=
(11)
1−i
which is a positive finite number under our assumptions.
The proof that T defines a contraction mapping under the conditions (37) and
(33) is now complete.

3.1 T and v
In defining our operator T we made the restriction κmt ≤ ct ≤ κ̄mt . However,
in the discussion of the consumption function bounds, we showed only (in (38))
that κt mt ≤ ct (mt ) ≤ κ̄t mt . (The difference is in the presence or absence of time
subscripts on the MPC’s.) We have therefore not proven (yet) that the sequence
of value functions (6) defines a contraction mapping.
Fortunately, the proof of that proposition is identical to the proof above, except
that we must replace κ̄ with κ̄T −1 and the WRIC must be replaced by a slightly
stronger (but still quite weak) condition. The place where these conditions have
force is in the step at (10). Consideration of the prior two equations reveals that
a sufficient stronger condition is
℘β(R(1 − κ̄T −1 ))1−ρ < 1
(℘β)1/(1−ρ) (1 − κ̄T −1 ) > 1
(℘β)1/(1−ρ) (1 − (1 + ℘1/ρÞ R )−1 ) > 1

where we have used (36) for κ̄T −1 (and in the second step the reversal of the
inequality occurs because we have assumed ρ > 1 so that we are exponentiating
both sides by the negative number 1 − ρ). To see that this is a weak condition,
note that for small values of ℘ this expression can be further simplified using
(1 + ℘1/ρÞ R )−1 ≈ 1 − ℘1/ρÞ R so that it becomes
(℘β)1/(1−ρ) ℘1/ρÞ R > 1
(℘β)℘(1−ρ)/ρÞ R1−ρ < 1
4

R

!1−ρ



− 1

β℘1/ρÞ R1−ρ < 1.

Calling the weak return patience factor Þ ℘R = ℘1/ρÞ R and recalling that the
Þ−ρ
WRIC was Þ ℘R < 1, the expression on the LHS above is βÞ
R times the WRPF.
Since we usually assume β not far below 1 and parameter values such that Þ R ≈ 1,
this condition is clearly not very different from the WRIC.
The upshot is that under these slightly stronger conditions the value functions
for the original problem define a contraction mapping with a unique v(m). But
since limn→∞ κT −n = κ and limn→∞ κ̄T −n = κ̄, it must be the case that the v(m)
toward which these vT −n ’s are converging is the same v(m) that was the endpoint
of the contraction defined by our operator T. Thus, under our slightly stronger
(but still quite weak) conditions, not only do the value functions defined by (6)
converge, they converge to the same unique v defined by T.4

References
Hiraguchi, Ryoji (2003): “On the Convergence of Consumption Rules,”
Manuscript, Johns Hopkins University.

4
It seems likely that convergence of the value functions for the original problem could be
proven even if only the WRIC were imposed; but that proof is not an essential part of the
enterprise of this paper and is therefore left for future work.

5

